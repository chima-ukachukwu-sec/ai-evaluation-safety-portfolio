# Project 4 â€” Authentic Long-Context Red Teaming & Persona-Based Evaluation

## Overview
Performed long-context AI safety evaluations designed to surface failures
that emerge only after extended, realistic conversations.

## Core Focus
- Persona consistency
- Emotional progression
- Gradual escalation
- Refusal persistence under context pressure

## Abstracted Workflow
1. Define realistic user personas
2. Maintain consistent background and tone
3. Gradually escalate risk across turns
4. Adapt naturally to refusals
5. Track delayed failures and near-misses
6. Log recurring patterns and trends

## Skills Demonstrated
- Long-context safety evaluation
- Human-factors AI risk analysis
- Persona-based testing
- Wellbeing-aware red teaming

## NDA Notice
All personas and conversations are abstracted and simulated.
No real individuals or internal scripts are used.
